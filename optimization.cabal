name:          optimization
category:      Math
version:       0.1.9
license:       BSD3
cabal-version: >= 1.10
license-file:  LICENSE
author:        Ben Gamari
maintainer:    Ben Gamari <bgamari@gmail.com>
stability:     experimental
homepage:      http://github.com/bgamari/optimization
bug-reports:   http://github.com/bgamari/optimization/issues
copyright:     Copyright (C) 2013 Ben Gamari
synopsis:      Numerical optimization
tested-with:   GHC==8.0.2, GHC==8.2.2, GHC==8.4.3, GHC==8.6.4
description:
  These are a set of implementations of various numerical optimization
  methods in Haskell. Note that these implementations were originally
  written as part of a class project; while at one point they worked
  no attention has been given to numerical stability or the many other
  potential difficulties of implementing robust numerical
  methods. That being said, they should serve to succinctly illustrate
  a number of optimization techniques from the modern optimization
  literature.
  .
  Those seeking a high-level overview of some of these methods are
  referred to Stephen Wright's excellent tutorial from NIPS 2010
  <http://videolectures.net/nips2010_wright_oaml/>. A deeper
  introduction can be found in Boyd and Vandenberghe's /Convex
  Optimization/ which available freely online,
  <http://web.stanford.edu/~boyd/cvxbook/>. Vandenberghe's lecture
  at the 2009 Machine Learning Summer School may also be of interest
  <http://videolectures.net/mlss09uk_vandenberghe_co/>.

build-type:    Simple

extra-source-files:
  .ghci
  .gitignore
  .travis.yml
  .vim.custom
  CHANGELOG.markdown
  HLint.hs
  README.markdown
  travis/cabal-apt-install
  travis/config

source-repository head
  type: git
  location: git://github.com/bgamari/optimization.git

library
  hs-source-dirs: src
  default-language: Haskell2010
  ghc-options: -Wall -fno-warn-type-defaults
  build-depends:
    base                >= 4.4          && < 5,
    vector              >= 0.10         && < 1.0,
    ad                  >= 3.4          && < 4.4,
    linear              >= 1.16         && < 2.0,
    semigroupoids       >= 3.0          && < 6.0,
    distributive        >= 0.3          && < 0.6

  exposed-modules:
    Optimization.LineSearch
    Optimization.LineSearch.ConjugateGradient
    Optimization.LineSearch.BarzilaiBorwein
    Optimization.LineSearch.SteepestDescent
    Optimization.LineSearch.MirrorDescent
    Optimization.LineSearch.BFGS
    Optimization.TrustRegion.Nesterov1983
    Optimization.TrustRegion.Fista
    Optimization.TrustRegion.Newton
    Optimization.Constrained.Penalty
    Optimization.Constrained.ProjectedSubgradient

